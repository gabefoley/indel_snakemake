Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	clean_fasta
	1	create_control_files
	2	run_grasp
	1	run_indelible
	1	summarise_indels
	6
Select jobs to execute...

[Thu Jan 28 14:25:53 2021]
rule run_grasp:
    input: indelible_output/cleaned_aln/5/1.fasta, indelible_output/5/cleaned_trees/1.nwk
    output: grasp_results/5/BEP/1, grasp_results/5/BEP/1/GRASP_ancestors.fasta, grasp_results/5/BEP/1/tree.nwk
    jobid: 1
    wildcards: taxon=5, method=BEP, rep=1

[Thu Jan 28 14:25:55 2021]
Finished job 1.
1 of 6 steps (17%) done
Select jobs to execute...

[Thu Jan 28 14:25:55 2021]
rule create_control_files:
    output: indelible/concatenated/5_control.txt
    jobid: 8
    wildcards: taxon=concatenated/5

[Thu Jan 28 14:25:55 2021]
Finished job 8.
2 of 6 steps (33%) done
Select jobs to execute...

[Thu Jan 28 14:25:55 2021]
rule run_indelible:
    input: indelible/concatenated/5_control.txt
    output: indelible_output/concatenated/5/cleaned_trees/1.nwk, indelible_output/concatenated/5/concatenated/5_TRUE_1.fasta
    jobid: 7
    wildcards: taxon=concatenated/5, rep=1

Waiting at most 100 seconds for missing files.
Terminating processes on user request, this might take some time.
Cancelling snakemake on user request.
